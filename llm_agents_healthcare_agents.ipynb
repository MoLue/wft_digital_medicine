{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5f1dc4d",
   "metadata": {},
   "source": [
    "# LLM Agents in Healthcare Administration\n",
    "\n",
    "*Author: Timo Lüders*\n",
    "\n",
    "This notebook teaches how to build simple LLM-based agents for healthcare administration workflows (e.g., appointment handling, billing questions) **without using external API keys**.\n",
    "\n",
    "You will:\n",
    "- Understand the difference between plain LLMs and agents.\n",
    "- Build a simple appointment assistant that can call Python \"tools\".\n",
    "- Add safety guardrails to keep the agent in an administrative scope.\n",
    "- Use BioBERT embeddings to route queries between multiple specialized agents.\n",
    "- (Optional, advanced) Add a small retrieval component for admin FAQs.\n",
    "\n",
    "> **Disclaimer:** This notebook is for educational purposes only. It is **not** a medical device and must not be used for real patient care or decision making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e44e7b",
   "metadata": {},
   "source": [
    "## 0. How to Use This Notebook\n",
    "\n",
    "- Run cells from top to bottom.\n",
    "- Read the explanations in Markdown cells.\n",
    "- Complete the **exercises** marked with ✅.\n",
    "- Many code cells contain `# TODO` comments where you should add or modify code.\n",
    "\n",
    "At the end, you should have a small multi-agent system that can:\n",
    "- Answer appointment questions.\n",
    "- Answer simple billing questions (on synthetic data).\n",
    "- Route queries to the right agent.\n",
    "- Refuse to answer clinical questions.\n",
    "\n",
    "A separate solutions notebook can provide example answers and full reference code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d4278d",
   "metadata": {},
   "source": [
    "## 1. Setup and Environment\n",
    "\n",
    "In this section we:\n",
    "- Install and import required Python packages.\n",
    "- Detect whether a GPU is available.\n",
    "- Briefly discuss the models used in this notebook.\n",
    "\n",
    "We will rely on **open-source models** only:\n",
    "- **BioGPT** as a biomedical generative language model.\n",
    "- **BioBERT** as a biomedical encoder for embeddings and routing.\n",
    "\n",
    "✅ **Exercise 1 (reflection)**: After running the setup cells, write a short note (2–3 sentences) describing which models you loaded and whether you are using CPU or GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9383ab06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Packages installed (or already present).\n"
     ]
    }
   ],
   "source": [
    "# 1.1 Install required packages (run once per session)\n",
    "\n",
    "!pip install -q transformers torch psutil\n",
    "\n",
    "# Optional: for similarity / math utilities\n",
    "!pip install -q numpy\n",
    "\n",
    "!pip install -q sacremoses protobuf\n",
    "\n",
    "\n",
    "print(\"Packages installed (or already present).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a628143a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Google Colab: False\n",
      "GPU available: False\n",
      "Approx. available system memory: 3.21 GB\n"
     ]
    }
   ],
   "source": [
    "# 1.2 Basic environment check\n",
    "\n",
    "import sys\n",
    "import psutil\n",
    "import torch\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"Running in Google Colab: {IN_COLAB}\")\n",
    "\n",
    "has_gpu = torch.cuda.is_available()\n",
    "print(f\"GPU available: {has_gpu}\")\n",
    "\n",
    "mem_gb = psutil.virtual_memory().available / 1e9\n",
    "print(f\"Approx. available system memory: {mem_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5104950b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "/Users/timo/Documents/SonstigeProjekte/wft_digital_medicine/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:798: UserWarning: Not enough free disk space to download the file. The expected file size is: 1560.78 MB. The target location /Users/timo/.cache/huggingface/hub/models--microsoft--biogpt/blobs only has 484.91 MB free disk space.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't load the model for 'microsoft/biogpt'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'microsoft/biogpt' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SonstigeProjekte/wft_digital_medicine/venv/lib/python3.12/site-packages/transformers/modeling_utils.py:1066\u001b[39m, in \u001b[36m_get_resolved_checkpoint_files\u001b[39m\u001b[34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001b[39m\n\u001b[32m   1065\u001b[39m         filename = _add_variant(WEIGHTS_NAME, variant)\n\u001b[32m-> \u001b[39m\u001b[32m1066\u001b[39m         resolved_archive_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1067\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcached_file_kwargs\u001b[49m\n\u001b[32m   1068\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1069\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename == _add_variant(WEIGHTS_NAME, variant):\n\u001b[32m   1070\u001b[39m     \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SonstigeProjekte/wft_digital_medicine/venv/lib/python3.12/site-packages/transformers/utils/hub.py:322\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[33;03mTries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    271\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m \u001b[33;03m```\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SonstigeProjekte/wft_digital_medicine/venv/lib/python3.12/site-packages/transformers/utils/hub.py:567\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    566\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, EntryNotFoundError):\n\u001b[32m--> \u001b[39m\u001b[32m567\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    569\u001b[39m resolved_files = [\n\u001b[32m    570\u001b[39m     _get_cache_file_to_return(path_or_repo_id, filename, cache_dir, revision) \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m full_filenames\n\u001b[32m    571\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SonstigeProjekte/wft_digital_medicine/venv/lib/python3.12/site-packages/transformers/utils/hub.py:479\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    477\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    478\u001b[39m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SonstigeProjekte/wft_digital_medicine/venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SonstigeProjekte/wft_digital_medicine/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1007\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m   1006\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1007\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SonstigeProjekte/wft_digital_medicine/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1168\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1167\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[32m-> \u001b[39m\u001b[32m1168\u001b[39m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.incomplete\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1180\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(pointer_path):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SonstigeProjekte/wft_digital_medicine/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1720\u001b[39m, in \u001b[36m_download_to_tmp_and_move\u001b[39m\u001b[34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[39m\n\u001b[32m   1719\u001b[39m     logger.debug(\u001b[33m\"\u001b[39m\u001b[33mXet Storage is enabled for this repo. Downloading file from Xet Storage..\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1720\u001b[39m     \u001b[43mxet_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1721\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1722\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1723\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1724\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1725\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisplayed_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1726\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1727\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SonstigeProjekte/wft_digital_medicine/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:626\u001b[39m, in \u001b[36mxet_get\u001b[39m\u001b[34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001b[39m\n\u001b[32m    624\u001b[39m     progress.update(progress_bytes)\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mdownload_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxet_download_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccess_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpiration_unix_epoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_refresher\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_refresher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Data processing error: CAS service error : IO Error: No space left on device (os error 28)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Load BioGPT for generation\u001b[39;00m\n\u001b[32m      7\u001b[39m biogpt_tokenizer = BioGptTokenizer.from_pretrained(\u001b[33m\"\u001b[39m\u001b[33mmicrosoft/biogpt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m biogpt_model = \u001b[43mBioGptForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmicrosoft/biogpt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhas_gpu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat16\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhas_gpu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoaded BioGPT model for generation.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Load BioBERT for embeddings / routing\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SonstigeProjekte/wft_digital_medicine/venv/lib/python3.12/site-packages/transformers/modeling_utils.py:277\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    279\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SonstigeProjekte/wft_digital_medicine/venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4900\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4890\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4891\u001b[39m     gguf_file\n\u001b[32m   4892\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4893\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28misinstance\u001b[39m(device_map, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map.values()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map)\n\u001b[32m   4894\u001b[39m ):\n\u001b[32m   4895\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   4896\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4897\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mloaded from GGUF files.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4898\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m4900\u001b[39m checkpoint_files, sharded_metadata = \u001b[43m_get_resolved_checkpoint_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4901\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4902\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4903\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4904\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4905\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4906\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4907\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4908\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4909\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4910\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4911\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4912\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4913\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4914\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_auto_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4920\u001b[39m is_sharded = sharded_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4921\u001b[39m is_quantized = hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SonstigeProjekte/wft_digital_medicine/venv/lib/python3.12/site-packages/transformers/modeling_utils.py:1160\u001b[39m, in \u001b[36m_get_resolved_checkpoint_files\u001b[39m\u001b[34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001b[39m\n\u001b[32m   1157\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m   1158\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1159\u001b[39m         \u001b[38;5;66;03m# For any other exception, we throw a generic error.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1160\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m   1161\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCan\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt load the model for \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. If you were trying to load it\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1162\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m from \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/models\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, make sure you don\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt have a local directory with the\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1163\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m same name. Otherwise, make sure \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is the correct path to a\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1164\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m directory containing a file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(WEIGHTS_NAME,\u001b[38;5;250m \u001b[39mvariant)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1165\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF2_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFLAX_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1166\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_local:\n\u001b[32m   1169\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mloading weights file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchive_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOSError\u001b[39m: Can't load the model for 'microsoft/biogpt'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'microsoft/biogpt' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack."
     ]
    }
   ],
   "source": [
    "# 1.3 Load open-source medical models: BioGPT (generator) and BioBERT (encoder)\n",
    "\n",
    "from transformers import BioGptTokenizer, BioGptForCausalLM\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load BioGPT for generation\n",
    "biogpt_tokenizer = BioGptTokenizer.from_pretrained(\"microsoft/biogpt\")\n",
    "\n",
    "biogpt_model = BioGptForCausalLM.from_pretrained(\n",
    "    \"microsoft/biogpt\",\n",
    "    device_map=\"auto\" if has_gpu else None,\n",
    "    torch_dtype=torch.float16 if has_gpu else torch.float32,\n",
    ")\n",
    "\n",
    "print(\"Loaded BioGPT model for generation.\")\n",
    "\n",
    "# Load BioBERT for embeddings / routing\n",
    "biobert_tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.2\")\n",
    "biobert_model = AutoModel.from_pretrained(\"dmis-lab/biobert-base-cased-v1.2\")\n",
    "\n",
    "if has_gpu:\n",
    "    biobert_model = biobert_model.to(\"cuda\")\n",
    "\n",
    "print(\"Loaded BioBERT model for embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b530f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4 Helper functions for generation and embeddings\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def generate_with_biogpt(prompt: str, max_new_tokens: int = 150) -> str:\n",
    "    \"\"\"Generate a response from BioGPT given a text prompt.\"\"\"\n",
    "    formatted_prompt = f\"Question: {prompt}\\n\\nAnswer:\"\n",
    "    inputs = biogpt_tokenizer(formatted_prompt, return_tensors=\"pt\")\n",
    "\n",
    "    if has_gpu:\n",
    "        inputs = {k: v.to(biogpt_model.device) for k, v in inputs.items()}\n",
    "\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = biogpt_model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.8,\n",
    "            top_p=0.92,\n",
    "            top_k=50,\n",
    "            repetition_penalty=1.2,\n",
    "            pad_token_id=biogpt_tokenizer.eos_token_id,\n",
    "            attention_mask=inputs.get(\"attention_mask\"),\n",
    "        )\n",
    "\n",
    "    full_text = biogpt_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    if \"Answer:\" in full_text:\n",
    "        return full_text.split(\"Answer:\", 1)[1].strip()\n",
    "    return full_text.strip()\n",
    "\n",
    "\n",
    "def get_biobert_embedding(text: str) -> torch.Tensor:\n",
    "    \"\"\"Return a single sentence embedding for the given text using BioBERT.\n",
    "\n",
    "    We use the [CLS] token embedding as a simple sentence representation.\n",
    "    \"\"\"\n",
    "    inputs = biobert_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    if has_gpu:\n",
    "        inputs = {k: v.to(biobert_model.device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = biobert_model(**inputs)\n",
    "\n",
    "    # CLS token embedding\n",
    "    emb = outputs.last_hidden_state[:, 0, :]  # shape: (1, hidden_dim)\n",
    "    return emb.squeeze(0).cpu()\n",
    "\n",
    "\n",
    "def cosine_similarity(a: torch.Tensor, b: torch.Tensor) -> float:\n",
    "    \"\"\"Compute cosine similarity between two 1D tensors.\"\"\"\n",
    "    a = a.view(-1)\n",
    "    b = b.view(-1)\n",
    "    return F.cosine_similarity(a.unsqueeze(0), b.unsqueeze(0)).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750108a0",
   "metadata": {},
   "source": [
    "✅ **Exercise 1**  \n",
    "Run the setup cells above and then, in a new Markdown cell, answer:\n",
    "- Which models did you load (names)?\n",
    "- Are you running on CPU or GPU?\n",
    "- How might this affect speed and what you can realistically run?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdaa835",
   "metadata": {},
   "source": [
    "## 2. From Plain LLM to Agent Concept\n",
    "\n",
    "In this section we:\n",
    "- Try a plain interaction with BioGPT (no tools).\n",
    "- Introduce the idea of an **agent**.\n",
    "- Start thinking about roles for different assistants.\n",
    "\n",
    "An **LLM agent** is more than just text-in/text-out: it can use tools (Python functions, APIs), follow goals, and be constrained to a specific role (e.g. clinic receptionist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9c66b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Plain BioGPT interaction\n",
    "\n",
    "example_prompt = \"What are common administrative tasks in a general medical practice?\"\n",
    "response = generate_with_biogpt(example_prompt, max_new_tokens=120)\n",
    "print(\"Prompt:\\n\", example_prompt)\n",
    "print(\"\\nBioGPT response:\\n\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed42fbf",
   "metadata": {},
   "source": [
    "✅ **Exercise 2**  \n",
    "In a new Markdown cell, define **two roles** for LLMs in a clinic:\n",
    "\n",
    "1. `ClinicReceptionBot` – handles only administrative questions (appointments, opening hours, contact info).\n",
    "2. `FinancialAssistantBot` – handles only billing and invoice questions.\n",
    "\n",
    "For each role, describe in 3–4 bullet points:\n",
    "- What the agent *can* do.\n",
    "- What it must **not** do (e.g. no clinical advice)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43507c4a",
   "metadata": {},
   "source": [
    "## 3. Synthetic Clinic Data and Python Tools\n",
    "\n",
    "We now create a tiny, fully synthetic dataset to simulate a clinic:\n",
    "- A set of patients (with fake IDs and names).\n",
    "- Doctors and their specialties.\n",
    "- Appointments with dates and times.\n",
    "\n",
    "On top of this, we implement small Python functions that our future agents can call as **tools**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607c6901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Define synthetic clinic data\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "patients = [\n",
    "    {\"patient_id\": \"P001\", \"name\": \"Alice Example\"},\n",
    "    {\"patient_id\": \"P002\", \"name\": \"Bob Sample\"},\n",
    "    {\"patient_id\": \"P003\", \"name\": \"Charlie Demo\"},\n",
    "]\n",
    "\n",
    "doctors = [\n",
    "    {\"doctor_id\": \"D001\", \"name\": \"Dr. Smith\", \"specialty\": \"General Practice\"},\n",
    "    {\"doctor_id\": \"D002\", \"name\": \"Dr. Brown\", \"specialty\": \"Internal Medicine\"},\n",
    "]\n",
    "\n",
    "# appointments: list of dicts with simple fields\n",
    "appointments = [\n",
    "    {\n",
    "        \"appointment_id\": \"A001\",\n",
    "        \"patient_id\": \"P001\",\n",
    "        \"doctor_id\": \"D001\",\n",
    "        \"datetime\": datetime.now() + timedelta(days=1, hours=9),\n",
    "        \"type\": \"check-up\",\n",
    "    },\n",
    "    {\n",
    "        \"appointment_id\": \"A002\",\n",
    "        \"patient_id\": \"P002\",\n",
    "        \"doctor_id\": \"D002\",\n",
    "        \"datetime\": datetime.now() + timedelta(days=2, hours=11),\n",
    "        \"type\": \"follow-up\",\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\"Patients: {len(patients)}, Doctors: {len(doctors)}, Appointments: {len(appointments)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f123d98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Helper functions to work with the clinic data\n",
    "\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "\n",
    "def list_available_slots(days_ahead: int = 7, doctor_id: Optional[str] = None) -> List[Dict]:\n",
    "    \"\"\"Return a list of available (fake) time slots in the next 'days_ahead' days.\n",
    "\n",
    "    This is a very simplified function: in a real system, you would consider\n",
    "    working hours, existing bookings, holidays, etc.\n",
    "    \"\"\"\n",
    "    now = datetime.now()\n",
    "    slots = []\n",
    "    for d in range(1, days_ahead + 1):\n",
    "        for hour in [9, 11, 14, 16]:  # simple fixed hours\n",
    "            slot_time = now + timedelta(days=d, hours=hour)\n",
    "            # skip if already booked for this doctor at this time\n",
    "            for appt in appointments:\n",
    "                if appt[\"datetime\"].date() == slot_time.date() and appt[\"datetime\"].hour == slot_time.hour:\n",
    "                    if doctor_id is None or appt[\"doctor_id\"] == doctor_id:\n",
    "                        break\n",
    "            else:\n",
    "                slots.append({\"datetime\": slot_time, \"doctor_id\": doctor_id or \"ANY\"})\n",
    "    return slots\n",
    "\n",
    "\n",
    "def book_appointment(patient_id: str, doctor_id: str, slot_datetime: datetime, appt_type: str = \"check-up\") -> Dict:\n",
    "    \"\"\"Book a new appointment if the slot is free.\n",
    "\n",
    "    Returns the created appointment dict.\n",
    "    \"\"\"\n",
    "    # NOTE: In Exercise 3B you will add a proper double-booking check here.\n",
    "    new_id = f\"A{len(appointments) + 1:03d}\"\n",
    "    appt = {\n",
    "        \"appointment_id\": new_id,\n",
    "        \"patient_id\": patient_id,\n",
    "        \"doctor_id\": doctor_id,\n",
    "        \"datetime\": slot_datetime,\n",
    "        \"type\": appt_type,\n",
    "    }\n",
    "    appointments.append(appt)\n",
    "    return appt\n",
    "\n",
    "\n",
    "def cancel_appointment(appointment_id: str) -> bool:\n",
    "    \"\"\"Cancel an appointment by ID. Returns True if found and removed.\"\"\"\n",
    "    for i, appt in enumerate(appointments):\n",
    "        if appt[\"appointment_id\"] == appointment_id:\n",
    "            del appointments[i]\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22382fd",
   "metadata": {},
   "source": [
    "✅ **Exercise 3A**  \n",
    "Implement a function `get_patient_appointments(patient_id: str)` that returns all appointments for that patient.\n",
    "\n",
    "- Write the function in the next code cell.\n",
    "- Test it with patient IDs like `\"P001\"` and `\"P003\"`.\n",
    "\n",
    "✅ **Exercise 3B**  \n",
    "Extend `book_appointment` so that it **refuses** to book an appointment if another appointment already exists for the same doctor at the same date and time.\n",
    "\n",
    "- If a conflict is detected, print a short message and return `None`.\n",
    "- Otherwise, book as normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed0ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Exercise 3A – implement get_patient_appointments\n",
    "\n",
    "def get_patient_appointments(patient_id: str) -> List[Dict]:\n",
    "    \"\"\"Return a list of appointments for the given patient.\n",
    "\n",
    "    TODO: implement the filtering logic.\n",
    "    \"\"\"\n",
    "    # Hint: iterate over 'appointments' and select those with matching patient_id.\n",
    "    raise NotImplementedError(\"Implement get_patient_appointments\")\n",
    "\n",
    "\n",
    "# TODO: Exercise 3B – extend book_appointment to prevent double-booking\n",
    "# You can modify the existing book_appointment function above, or\n",
    "# write a new version here and replace the old one.\n",
    "\n",
    "print(\"Exercise 3A/3B: Implement and test your functions above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bada9c9",
   "metadata": {},
   "source": [
    "## 4. A Single Tool-Using Appointment Agent\n",
    "\n",
    "We now build our first **agent**:\n",
    "- It has a clear role: appointment assistant for a GP practice.\n",
    "- It can call our Python tools (e.g. list slots, book appointments).\n",
    "- It uses BioGPT to generate user-facing answers.\n",
    "\n",
    "The orchestration (\"when to call which tool\") is implemented in Python to keep things transparent and safe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15449fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 System prompt for the appointment agent\n",
    "\n",
    "APPOINTMENT_AGENT_SYSTEM_PROMPT = \"\"\"\n",
    "You are an appointment scheduling assistant for a general medical practice.\n",
    "\n",
    "Your responsibilities:\n",
    "- Help patients find and book suitable appointment times.\n",
    "- Help patients view and cancel existing synthetic appointments.\n",
    "- Ask follow-up questions if important information is missing (e.g. preferred date or doctor).\n",
    "\n",
    "Your limitations:\n",
    "- You MUST NOT provide medical diagnoses or treatment recommendations.\n",
    "- You MUST NOT interpret symptoms or lab values.\n",
    "- If the user asks for medical advice, you must say you cannot answer that and suggest contacting a clinician.\n",
    "\n",
    "Always be concise and polite.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"Appointment agent system prompt defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e21561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Simple rule-based action selection (no ML yet)\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class AppointmentAction(str, Enum):\n",
    "    NEW = \"new_appointment\"\n",
    "    RESCHEDULE = \"reschedule\"\n",
    "    CANCEL = \"cancel\"\n",
    "    VIEW = \"view\"\n",
    "    OTHER = \"other\"\n",
    "\n",
    "\n",
    "def decide_appointment_action(user_message: str) -> AppointmentAction:\n",
    "    \"\"\"Very simple rule-based classifier for appointment-related intents.\n",
    "\n",
    "    TODO (Exercise 4B): Refine these rules or add new ones based on examples.\n",
    "    \"\"\"\n",
    "    text = user_message.lower()\n",
    "    if any(word in text for word in [\"book\", \"schedule\", \"make an appointment\", \"new appointment\"]):\n",
    "        return AppointmentAction.NEW\n",
    "    if any(word in text for word in [\"reschedule\", \"move\", \"change time\"]):\n",
    "        return AppointmentAction.RESCHEDULE\n",
    "    if any(word in text for word in [\"cancel\", \"delete appointment\"]):\n",
    "        return AppointmentAction.CANCEL\n",
    "    if any(word in text for word in [\"see my appointments\", \"view appointments\", \"what appointments\"]):\n",
    "        return AppointmentAction.VIEW\n",
    "    return AppointmentAction.OTHER\n",
    "\n",
    "\n",
    "print(\"Rule-based decide_appointment_action defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2c4c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 A simple appointment agent loop using tools + BioGPT\n",
    "\n",
    "def run_appointment_agent(user_message: str) -> str:\n",
    "    \"\"\"Handle a user message with the appointment agent.\n",
    "\n",
    "    - Decide which action to take (NEW / RESCHEDULE / CANCEL / VIEW / OTHER).\n",
    "    - Optionally call Python tools on the synthetic data.\n",
    "    - Use BioGPT to generate the final answer.\n",
    "    \"\"\"\n",
    "    action = decide_appointment_action(user_message)\n",
    "\n",
    "    # For simplicity we do not implement full multi-turn slot-filling here.\n",
    "    # We will call very simple tools and pass their results to the LLM.\n",
    "\n",
    "    tool_context = \"\"\n",
    "\n",
    "    if action == AppointmentAction.VIEW:\n",
    "        # For demo purposes, show all appointments\n",
    "        lines = []\n",
    "        for appt in appointments:\n",
    "            lines.append(\n",
    "                f\"Appointment {appt['appointment_id']}: patient {appt['patient_id']} with {appt['doctor_id']} at {appt['datetime']} ({appt['type']})\"\n",
    "            )\n",
    "        tool_context = \"\\n\".join(lines) or \"No appointments found.\"\n",
    "\n",
    "    # NOTE: Booking/rescheduling/cancel flows can be expanded as an exercise.\n",
    "\n",
    "    prompt = f\"\"\"{APPOINTMENT_AGENT_SYSTEM_PROMPT}\n",
    "\n",
    "User message: \"{user_message}\"\n",
    "\n",
    "Relevant appointment system information:\n",
    "{tool_context or 'No additional information fetched.'}\n",
    "\n",
    "Write a concise answer to the user, following your responsibilities and limitations.\n",
    "\"\"\"\n",
    "\n",
    "    return generate_with_biogpt(prompt, max_new_tokens=200)\n",
    "\n",
    "\n",
    "# Quick demo\n",
    "example_user_message = \"Can you show me my upcoming appointments?\"\n",
    "print(run_appointment_agent(example_user_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e16f9a",
   "metadata": {},
   "source": [
    "✅ **Exercise 4A**  \n",
    "Modify `APPOINTMENT_AGENT_SYSTEM_PROMPT` so that the agent **always** confirms the appointment details (date, time, doctor) before booking a new appointment.\n",
    "\n",
    "✅ **Exercise 4B**  \n",
    "Refine `decide_appointment_action` by:\n",
    "- Adding more keywords.\n",
    "- Testing it on at least 5 example sentences and checking if the chosen action makes sense.\n",
    "\n",
    "You can keep your tests in a separate code cell (e.g. a small list of messages you iterate over)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dde1a48",
   "metadata": {},
   "source": [
    "## 5. Safety and Scope Limits\n",
    "\n",
    "In healthcare, we must be very clear about what the agent is **allowed** to do.\n",
    "\n",
    "In this notebook, our agents are limited to **administrative** tasks:\n",
    "- Appointments (booking, viewing, cancelling).\n",
    "- Simple billing/invoice questions (later).\n",
    "\n",
    "They must **not**:\n",
    "- Diagnose conditions.\n",
    "- Recommend treatments or medication dosages.\n",
    "- Interpret symptoms or lab results.\n",
    "\n",
    "We implement a simple text-based safety filter to detect likely clinical questions and block them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e4398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Simple safety filter for clinical questions\n",
    "\n",
    "CLINICAL_KEYWORDS = [\n",
    "    \"diagnose\",\n",
    "    \"diagnosis\",\n",
    "    \"should I take\",\n",
    "    \"medication\",\n",
    "    \"dose\",\n",
    "    \"dosage\",\n",
    "    \"side effect\",\n",
    "    \"is this cancer\",\n",
    "    \"treatment\",\n",
    "    \"symptom\",\n",
    "]\n",
    "\n",
    "\n",
    "def is_clinical_question(text: str) -> bool:\n",
    "    lower = text.lower()\n",
    "    return any(keyword in lower for keyword in CLINICAL_KEYWORDS)\n",
    "\n",
    "\n",
    "def handle_with_safety_filter(user_message: str) -> str:\n",
    "    \"\"\"Apply safety filter, then call the appointment agent if safe.\"\"\"\n",
    "    if is_clinical_question(user_message):\n",
    "        return (\n",
    "            \"I am only allowed to help with administrative questions (appointments, billing, etc.). \"\n",
    "            \"For medical questions about symptoms, diagnoses, or treatments, please contact a healthcare professional.\"\n",
    "        )\n",
    "    return run_appointment_agent(user_message)\n",
    "\n",
    "\n",
    "# Quick test\n",
    "for msg in [\n",
    "    \"Can you book an appointment for me tomorrow?\",\n",
    "    \"What medication should I take for high blood pressure?\",\n",
    "]:\n",
    "    print(\"\\nUser:\", msg)\n",
    "    print(\"Assistant:\", handle_with_safety_filter(msg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3091d8",
   "metadata": {},
   "source": [
    "✅ **Exercise 5**  \n",
    "Extend the safety filter:\n",
    "- Add at least 3 more keywords/phrases to `CLINICAL_KEYWORDS`.\n",
    "- Create a list of 6–8 test messages (some clinical, some administrative).\n",
    "- For each message, print whether `is_clinical_question` returns `True` and whether you agree.\n",
    "\n",
    "Reflect briefly in Markdown on any **false positives** or **false negatives** you observe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95eb3e4",
   "metadata": {},
   "source": [
    "## 6. Using BioBERT for Intent and Routing\n",
    "\n",
    "So far, our appointment agent used **hand-written rules** (`decide_appointment_action`).\n",
    "\n",
    "Now we use **BioBERT embeddings** to classify messages into broader intent categories:\n",
    "- `admin_appointments`\n",
    "- `billing`\n",
    "- `intake` (non-diagnostic symptom collection)\n",
    "\n",
    "This will later allow us to route messages to different specialized agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a5dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Define intent labels and pre-compute embeddings\n",
    "\n",
    "INTENT_LABELS = {\n",
    "    \"admin_appointments\": \"Questions about appointments, scheduling, rescheduling, or cancelling visits.\",\n",
    "    \"billing\": \"Questions about invoices, payments, insurance coverage, and costs.\",\n",
    "    \"intake\": \"Questions where patients describe symptoms or reasons for visit, but the agent should only collect information, not diagnose.\",\n",
    "}\n",
    "\n",
    "intent_label_embeddings = {\n",
    "    label: get_biobert_embedding(description)\n",
    "    for label, description in INTENT_LABELS.items()\n",
    "}\n",
    "\n",
    "print(\"Computed BioBERT embeddings for intent labels:\")\n",
    "for label in intent_label_embeddings:\n",
    "    print(\"-\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb65569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 Routing function using cosine similarity\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def route_intent(user_message: str) -> Tuple[str, float]:\n",
    "    \"\"\"Return (best_label, similarity_score) for the user_message.\"\"\"\n",
    "    emb = get_biobert_embedding(user_message)\n",
    "    best_label = None\n",
    "    best_score = -1.0\n",
    "    for label, label_emb in intent_label_embeddings.items():\n",
    "        score = cosine_similarity(emb, label_emb)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_label = label\n",
    "    return best_label, best_score\n",
    "\n",
    "\n",
    "# Quick demo\n",
    "examples = [\n",
    "    \"I need to change my appointment from Monday to Wednesday.\",\n",
    "    \"Why did I get two invoices for the same visit?\",\n",
    "    \"I have chest pain and shortness of breath, what should I do?\",\n",
    "]\n",
    "\n",
    "for text in examples:\n",
    "    label, score = route_intent(text)\n",
    "    print(f\"\\nText: {text}\\nRouted to: {label} (similarity={score:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ace9755",
   "metadata": {},
   "source": [
    "✅ **Exercise 6**  \n",
    "- Add at least 3 more example texts to the list in the routing demo.\n",
    "- For each, check if the chosen label makes sense.\n",
    "- (Advanced) Add a fourth label, e.g. `\"general_info\"`, with a suitable description, and update `INTENT_LABELS` and the demo.\n",
    "\n",
    "Briefly reflect in Markdown on one case where the routing was not ideal and how you might improve it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c14560b",
   "metadata": {},
   "source": [
    "## 7. Multi-Agent Orchestration\n",
    "\n",
    "We now create multiple specialized agents:\n",
    "\n",
    "- `AdminAgent` – handles appointment-related questions using our tools.\n",
    "- `BillingAgent` – answers questions about invoices and costs on a small synthetic dataset.\n",
    "- `IntakeAgent` – collects structured symptom information (without diagnosis).\n",
    "\n",
    "A **coordinator** will:\n",
    "1. Apply the safety filter.\n",
    "2. Use BioBERT-based routing (`route_intent`).\n",
    "3. Call the appropriate agent.\n",
    "\n",
    "All agents still use BioGPT for final answer generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a1568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Synthetic billing data\n",
    "\n",
    "billing_records = [\n",
    "    {\"invoice_id\": \"INV001\", \"patient_id\": \"P001\", \"amount\": 80.0, \"description\": \"GP consultation\", \"status\": \"paid\"},\n",
    "    {\"invoice_id\": \"INV002\", \"patient_id\": \"P001\", \"amount\": 40.0, \"description\": \"Lab tests\", \"status\": \"open\"},\n",
    "    {\"invoice_id\": \"INV003\", \"patient_id\": \"P002\", \"amount\": 120.0, \"description\": \"Specialist visit\", \"status\": \"open\"},\n",
    "]\n",
    "\n",
    "\n",
    "def get_patient_billing_summary(patient_id: str) -> str:\n",
    "    \"\"\"Return a human-readable summary of billing records for a patient.\"\"\"\n",
    "    records = [r for r in billing_records if r[\"patient_id\"] == patient_id]\n",
    "    if not records:\n",
    "        return f\"No billing records found for patient {patient_id}.\"\n",
    "    lines = []\n",
    "    for r in records:\n",
    "        lines.append(\n",
    "            f\"Invoice {r['invoice_id']}: {r['description']} — {r['amount']} EUR (status: {r['status']})\"\n",
    "        )\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219e6f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2 Specialized agent runners\n",
    "\n",
    "BILLING_AGENT_SYSTEM_PROMPT = \"\"\"\n",
    "You are a billing assistant for a small medical clinic.\n",
    "\n",
    "- You can see synthetic billing information such as invoice IDs, amounts, and payment status.\n",
    "- You explain invoices in simple language.\n",
    "- You cannot change or create real invoices.\n",
    "- You do not give any clinical or treatment advice.\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "INTAKE_AGENT_SYSTEM_PROMPT = \"\"\"\n",
    "You are an intake assistant.\n",
    "\n",
    "Your job is to collect structured information about why a patient is seeking care.\n",
    "\n",
    "- Ask clear follow-up questions about symptoms (onset, duration, severity, triggers).\n",
    "- Summarize the information in a structured way.\n",
    "- Do NOT provide diagnoses or treatment recommendations.\n",
    "- Encourage the patient to discuss their symptoms with a clinician.\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def run_admin_agent(user_message: str) -> str:\n",
    "    \"\"\"Currently this just calls our appointment agent with safety filter.\"\"\"\n",
    "    return handle_with_safety_filter(user_message)\n",
    "\n",
    "\n",
    "def run_billing_agent(user_message: str, patient_id: str = \"P001\") -> str:\n",
    "    \"\"\"Use synthetic billing data and BioGPT to answer billing questions.\n",
    "\n",
    "    TODO (Exercise 7A): make this function smarter (e.g., parse invoice IDs from the message).\n",
    "    \"\"\"\n",
    "    billing_info = get_patient_billing_summary(patient_id)\n",
    "\n",
    "    prompt = f\"\"\"{BILLING_AGENT_SYSTEM_PROMPT}\n",
    "\n",
    "User message: \"{user_message}\"\n",
    "\n",
    "Synthetic billing information for patient {patient_id}:\n",
    "{billing_info}\n",
    "\n",
    "Explain the situation to the user in simple terms.\n",
    "\"\"\"\n",
    "    return generate_with_biogpt(prompt, max_new_tokens=200)\n",
    "\n",
    "\n",
    "def run_intake_agent(user_message: str) -> str:\n",
    "    \"\"\"Use BioGPT to collect and summarize symptom information.\n",
    "\n",
    "    For simplicity, we use single-turn messages here.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"{INTAKE_AGENT_SYSTEM_PROMPT}\n",
    "\n",
    "Patient message: \"{user_message}\"\n",
    "\n",
    "Respond with a short clarification or summary that could be handed to a clinician.\n",
    "Remember: do not diagnose or recommend treatments.\n",
    "\"\"\"\n",
    "    return generate_with_biogpt(prompt, max_new_tokens=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68050a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.3 Coordinator that routes between agents\n",
    "\n",
    "def coordinator(user_message: str, patient_id: str = \"P001\") -> str:\n",
    "    \"\"\"Top-level function:\n",
    "    - Apply safety filter.\n",
    "    - Route via BioBERT to admin / billing / intake.\n",
    "    - Call the corresponding agent.\n",
    "    \"\"\"\n",
    "    if is_clinical_question(user_message):\n",
    "        # Clinical questions are blocked at the top level\n",
    "        return (\n",
    "            \"I can only help with administrative questions and general intake information. \"\n",
    "            \"For medical concerns, please contact a healthcare professional or emergency services if needed.\"\n",
    "        )\n",
    "\n",
    "    label, score = route_intent(user_message)\n",
    "    debug_info = f\"[DEBUG] Routed to: {label} (similarity={score:.3f})\\n\"\n",
    "\n",
    "    if label == \"admin_appointments\":\n",
    "        answer = run_admin_agent(user_message)\n",
    "    elif label == \"billing\":\n",
    "        answer = run_billing_agent(user_message, patient_id=patient_id)\n",
    "    elif label == \"intake\":\n",
    "        answer = run_intake_agent(user_message)\n",
    "    else:\n",
    "        # Fallback to admin agent\n",
    "        answer = run_admin_agent(user_message)\n",
    "\n",
    "    return debug_info + answer\n",
    "\n",
    "\n",
    "# Quick multi-agent demo\n",
    "messages = [\n",
    "    \"I need to reschedule my check-up with the doctor.\",\n",
    "    \"Why do I have two open invoices?\",\n",
    "    \"I have had a strong headache and blurred vision for 3 days.\",\n",
    "]\n",
    "\n",
    "for msg in messages:\n",
    "    print(\"\\nUser:\", msg)\n",
    "    print(\"Assistant:\\n\", coordinator(msg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9900e968",
   "metadata": {},
   "source": [
    "✅ **Exercise 7A**  \n",
    "Improve `run_billing_agent`:\n",
    "- Try to detect specific invoice IDs mentioned in the user message (e.g. `\"INV002\"`).\n",
    "- If an ID is mentioned, focus the explanation on that invoice.\n",
    "- Otherwise, provide a general overview as in the current version.\n",
    "\n",
    "✅ **Exercise 7B**  \n",
    "Modify `coordinator` so that the debug information (routed label and similarity) is only shown when a variable `SHOW_DEBUG = True`.\n",
    "\n",
    "Test your improved coordinator with at least 5 different user messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1322b621",
   "metadata": {},
   "source": [
    "## 8. Optional: Mini RAG for Admin FAQs (Advanced, Optional)\n",
    "\n",
    "If you have time and interest, you can extend your system with a tiny retrieval component:\n",
    "- Create a small list of FAQ entries about clinic policies (cancellation, billing, opening hours).\n",
    "- Embed them with BioBERT.\n",
    "- For each user question, retrieve the most similar FAQ entries and include them in the prompt to BioGPT.\n",
    "\n",
    "This is a simple form of **Retrieval-Augmented Generation (RAG)** for administrative knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48088a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1 (Optional) Tiny FAQ corpus and retrieval\n",
    "\n",
    "FAQ_ENTRIES = [\n",
    "    \"You can cancel or reschedule an appointment up to 24 hours before without any fee.\",\n",
    "    \"If you miss an appointment without notice, a small no-show fee may be charged.\",\n",
    "    \"Invoices can be paid by bank transfer or credit card within 30 days.\",\n",
    "    \"Our clinic is open from 8:00 to 17:00 on weekdays.\",\n",
    "]\n",
    "\n",
    "faq_embeddings = [get_biobert_embedding(text) for text in FAQ_ENTRIES]\n",
    "\n",
    "\n",
    "def retrieve_faqs(query: str, top_k: int = 2) -> list:\n",
    "    q_emb = get_biobert_embedding(query)\n",
    "    scores = [cosine_similarity(q_emb, e) for e in faq_embeddings]\n",
    "    ranked = sorted(zip(FAQ_ENTRIES, scores), key=lambda x: x[1], reverse=True)\n",
    "    return ranked[:top_k]\n",
    "\n",
    "\n",
    "def answer_with_faq_rag(user_message: str) -> str:\n",
    "    retrieved = retrieve_faqs(user_message, top_k=2)\n",
    "    context_lines = [f\"- {text} (score={score:.3f})\" for text, score in retrieved]\n",
    "    context = \"\\n\".join(context_lines)\n",
    "\n",
    "    prompt = f\"\"\"You are an administrative assistant for a clinic.\n",
    "\n",
    "User question: \"{user_message}\"\n",
    "\n",
    "Relevant policy information:\n",
    "{context}\n",
    "\n",
    "Use only the information above to answer the user's question. If something is unclear, say so.\n",
    "\"\"\"\n",
    "    return generate_with_biogpt(prompt, max_new_tokens=200)\n",
    "\n",
    "\n",
    "# Quick demo\n",
    "print(answer_with_faq_rag(\"What happens if I miss my appointment?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98acb65",
   "metadata": {},
   "source": [
    "✅ **Exercise 8 (optional)**  \n",
    "- Add at least 2 new FAQ entries.\n",
    "- Try several user questions and look at which FAQs were retrieved.\n",
    "- Adjust the number of FAQs or examine the similarity scores to improve relevance.\n",
    "\n",
    "Briefly document one example where RAG clearly improved the answer compared to not using FAQs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f2c2e3",
   "metadata": {},
   "source": [
    "## 9. Evaluation and Reflection\n",
    "\n",
    "In this final section, you should:\n",
    "- Test your system with a small set of diverse messages.\n",
    "- Check that routing and safety behave as expected.\n",
    "- Reflect on limitations and potential risks.\n",
    "\n",
    "✅ **Exercise 9**  \n",
    "1. Create a list of at least 6 test messages that cover:\n",
    "   - Admin appointments\n",
    "   - Billing\n",
    "   - Intake-like symptom descriptions\n",
    "   - Clearly clinical questions that should be blocked\n",
    "2. Run them through `coordinator` and record the outputs.\n",
    "3. In Markdown, list:\n",
    "   - 3 potential risks of using such agents in real clinics.\n",
    "   - 2 ideas to make them safer (technical or organizational)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d19326d",
   "metadata": {},
   "source": [
    "## 10. Summary and Next Steps\n",
    "\n",
    "In this notebook you:\n",
    "- Loaded open-source biomedical models (BioGPT, BioBERT) without any external API keys.\n",
    "- Built Python \"tools\" on top of a small synthetic clinic dataset.\n",
    "- Created an appointment agent that can use tools and respects a clear scope.\n",
    "- Implemented a simple safety filter to block clinical questions.\n",
    "- Used BioBERT embeddings to route between multiple specialized agents.\n",
    "- Optionally, experimented with a tiny RAG setup for administrative FAQs.\n",
    "\n",
    "**Next steps:**\n",
    "- Explore the separate notebook on building a small Streamlit UI for your agents.\n",
    "- Think about how you would log agent decisions and enable human oversight.\n",
    "- Consider how real-world constraints (regulation, data protection, governance) would further shape such systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
