{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoLue/wft_digital_medicine/blob/main/dm_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook Overview: NLP x Transformers\n",
        "This notebook explores the progression from traditional Natural Language Processing (NLP) pipelines to modern Transformer-based models. You’ll start by learning the fundamental steps of an NLP pipeline, such as tokenization, Part-of-Speech tagging, and Named Entity Recognition (NER), using SpaCy. Then, you’ll transition to Transformer models, like BERT and GPT, to tackle tasks such as text generation and advanced NER. Both approaches will be applied to real-world examples, including analyzing medical documents. Finally, we’ll compare the strengths and limitations of SpaCy and Transformers, highlighting when to use each. By the end, you’ll have practical skills in both traditional NLP and modern Transformers, understanding how they complement each other in different contexts."
      ],
      "metadata": {
        "id": "ncGsL8G6UL2e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP Pipeline\n",
        "\n",
        "## **Introduction to Natural Language Processing (NLP)**\n",
        "\n",
        "Natural Language Processing (NLP) is a subfield of Artificial Intelligence (AI) that focuses on enabling computers to understand, interpret, and generate human language. NLP bridges the gap between human communication and machine understanding, making it possible to extract insights, automate processes, and interact with text and speech data effectively.\n",
        "\n",
        "### **Applications of NLP**\n",
        "NLP has a wide range of real-world applications, including:\n",
        "- **Sentiment Analysis**: Determining the sentiment (positive, negative, neutral) in customer reviews or social media posts.\n",
        "- **Named Entity Recognition (NER)**: Identifying entities like names, dates, or locations in unstructured text.\n",
        "- **Machine Translation**: Translating text from one language to another, e.g., Google Translate.\n",
        "- **Text Summarization**: Generating concise summaries of lengthy documents.\n",
        "- **Chatbots and Virtual Assistants**: Powering conversational systems like Siri or Alexa.\n",
        "- **Medical Text Analysis**: Extracting clinical information, such as diagnoses or prescribed medications, from medical notes.\n",
        "\n",
        "---\n",
        "\n",
        "## **What is an NLP Pipeline?**\n",
        "\n",
        "An NLP pipeline is a step-by-step process to transform raw text into meaningful data that machines can analyze. Each step in the pipeline performs a specific task to preprocess, analyze, or extract information from text. The pipeline is modular, meaning you can adjust or add steps depending on the complexity of the task.\n",
        "\n",
        "### **Steps in a Typical NLP Pipeline**\n",
        "Here’s an overview of the common steps involved in an NLP pipeline:\n",
        "\n",
        "1. **Tokenization**\n",
        "   - The process of breaking down text into smaller units called tokens, such as words or subwords.\n",
        "   \n",
        "\n",
        "2. **Sentence Segmentation**\n",
        "   - Dividing text into individual sentences to enable sentence-level analysis.\n",
        "\n",
        "3. **Part-of-Speech (PoS) Tagging**\n",
        "   - Assigning grammatical roles (e.g., noun, verb, adjective) to each token.\n",
        "\n",
        "\n",
        "4. **Stop Word Removal**\n",
        "   - Filtering out commonly used words (like \"the\", \"and\", \"is\") that carry little meaning for the analysis.\n",
        "\n",
        "5. **Lemmatization**\n",
        "   - Reducing words to their base or dictionary form (lemma).  \n",
        "\n",
        "\n",
        "6. **Dependency Parsing**\n",
        "   - Analyzing the grammatical structure of sentences to identify relationships between words.  \n",
        "\n",
        "7. **Named Entity Recognition (NER)**\n",
        "   - Identifying and categorizing entities such as names, dates, organizations, or medications.\n",
        "\n",
        "\n",
        "8. **Coreference Resolution**\n",
        "   - Resolving references within text to identify when different expressions refer to the same entity.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **Why Do We Need an NLP Pipeline?**\n",
        "\n",
        "Text data in its raw form is unstructured and challenging for machines to process. An NLP pipeline:\n",
        "- **Transforms raw text into structured data** that can be analyzed or used in machine learning models.\n",
        "- **Reduces noise** by filtering irrelevant information, such as stop words.\n",
        "- **Extracts meaningful patterns** from text, such as grammatical relationships, key entities, or sentiments.\n",
        "- **Provides flexibility** to customize the pipeline based on the specific task (e.g., sentiment analysis, summarization)."
      ],
      "metadata": {
        "id": "6_Y_7vVTQk1k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Started"
      ],
      "metadata": {
        "id": "x0M8ijgiUiNe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLZT8eulcIqX"
      },
      "outputs": [],
      "source": [
        "! pip install spacy\n",
        "! pip install coreferee\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EZtB5FacIqa"
      },
      "outputs": [],
      "source": [
        "\n",
        "! python -m spacy download en_core_web_sm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xI1xncO4cIqa"
      },
      "outputs": [],
      "source": [
        "! python -m coreferee install en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4qLjotJcIqa"
      },
      "source": [
        "Spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooR2SdhBcIqe"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "import nltk\n",
        "\n",
        "from nltk.stem.porter import *\n",
        "\n",
        "# load the text corpus of your choice. We will work here with the downloaded small core\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "example = \"In the U.K., Joe Biden and Angela Merkel talked about the current economic situation. They both think the inflation rate will not drop in the near future!\"\n",
        "\n",
        "example_doc = nlp(example)\n",
        "example_doc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykqth-NTcIqf"
      },
      "source": [
        "## Tokenization\n",
        "What is Tokenization?\n",
        "Tokenization is the first step in any NLP pipeline. It involves breaking down a text into smaller units, called tokens. Tokens can be words, punctuation marks, or numbers.\n",
        "\n",
        "Why is Tokenization important?\n",
        "Tokenization allows us to preprocess and analyze text in manageable pieces. It’s foundational for further processing like Part-of-Speech (PoS) tagging, Named Entity Recognition (NER), and dependency parsing. Modern NLP tools like SpaCy handle tokenization efficiently, even for edge cases such as abbreviations or contractions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8ddcUNGcIqf"
      },
      "outputs": [],
      "source": [
        "for token in example_doc:\n",
        "    print(token.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oj53NOFWcIqf"
      },
      "source": [
        "## Sentence Segmentation\n",
        "What is Sentence Segmentation?\n",
        "Sentence segmentation is the process of splitting a document into sentences.\n",
        "\n",
        "\n",
        "Why is Sentence Segmentation important?\n",
        "Segmenting a text into sentences makes it easier to analyze the structure and meaning of a document. In medical text, this helps separate observations, instructions, and findings into discrete, analyzable units. SpaCy performs sentence segmentation automatically as part of its pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Rx0r0MVcIqf"
      },
      "outputs": [],
      "source": [
        "for sent in example_doc.sents:\n",
        "    print(sent.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBO5K7dncIqf"
      },
      "source": [
        "## Part-of-Speech Tagging\n",
        "Part-of-Speech tagging assigns a grammatical role to each token in a sentence, such as noun, verb, or adjective.\n",
        "\n",
        "Why is PoS Tagging important?\n",
        "PoS tagging helps understand the grammatical structure of a sentence and can be used to extract patterns or relationships, such as identifying actions (verbs) or key entities (nouns). It’s also a precursor to tasks like dependency parsing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oj9WUpX5cIqg"
      },
      "outputs": [],
      "source": [
        "for token in example_doc:\n",
        "    print (f\"{token.text : <15}{token.pos_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEjGNJ43cIqg"
      },
      "source": [
        "##Lemmatization\n",
        "Lemmatization is the process of reducing words to their base or dictionary form, called a lemma. For example:\n",
        "- \"running\" → \"run\"\n",
        "- \"patients\" → \"patient\"\n",
        "\n",
        "Why is Lemmatization important?\n",
        "Lemmatization ensures consistency in text analysis by normalizing words to their base forms. This is particularly useful when analyzing medical notes, where different forms of the same word (e.g., \"diagnosed\", \"diagnosis\") should be treated as the same concept. Unlike stemming, lemmatization ensures that the resulting words are valid dictionary entries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdqhxRxVcIqg"
      },
      "outputs": [],
      "source": [
        "stemmer = PorterStemmer()\n",
        "for token in example_doc:\n",
        "    print (f\"{token.text : <15}{token.lemma_  : <15}{stemmer.stem(token.text)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p6rvR2TcIqg"
      },
      "source": [
        "## Stop Words\n",
        "Stop words are common words such as \"the\", \"is\", \"and\", or \"in\" that usually carry little meaning on their own. Removing stop words can help focus on the more meaningful parts of a text.\n",
        "\n",
        "Why is Stop Word Removal important?\n",
        "Filtering out stop words reduces noise in text data and can improve the performance of downstream tasks. However, in specialized domains like medicine, some stop words (e.g., \"with\", \"of\") may carry significant meaning and should be retained. SpaCy allows customization of the stop word list to suit your needs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnyyceelcIqg"
      },
      "outputs": [],
      "source": [
        "SW = list(nlp.Defaults.stop_words)\n",
        "print('First 20 stop-words: ', SW[:20])\n",
        "print('Number of stop-words: ', len(SW))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cT4ED0oMcIqg"
      },
      "source": [
        "##Dependency Parsing\n",
        "Dependency parsing analyzes the grammatical structure of a sentence and identifies relationships between words.\n",
        "\n",
        "Why is Dependency Parsing important?\n",
        "Dependency parsing helps in understanding how different parts of a sentence are connected. This is critical for extracting meaningful relationships, such as determining who performed an action or what an action was performed on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hZ1tQejcIqg"
      },
      "outputs": [],
      "source": [
        "sents = list(example_doc.sents)\n",
        "sent = sents[0]\n",
        "\n",
        "for token in sent:\n",
        "    print (f\"{token.text : <15}{token.dep_ : <15}{spacy.explain(token.dep_)}\")\n",
        "\n",
        "displacy.render(sent, style=\"dep\", jupyter=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyEpeOSZcIqh"
      },
      "source": [
        "## Named Entity Recognition\n",
        "Named Entity Recognition (NER) identifies and categorizes specific entities in a text, such as names of medications, diseases, or dosages. For example, in the text:\n",
        "\n",
        "\n",
        "Why is NER important?\n",
        "In medical contexts, NER helps extract structured information from unstructured text, such as identifying medications, symptoms, or procedures in clinical notes. SpaCy and its extensions (like SciSpacy) are particularly effective for this task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J99FtUp9cIqh"
      },
      "outputs": [],
      "source": [
        "for ent in example_doc.ents:\n",
        "    print (f\"{ent.text : <20}{ent.label_ : <15}{spacy.explain(ent.label_)}\")\n",
        "\n",
        "displacy.render(example_doc, style=\"ent\", jupyter=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UqorP8_cIqh"
      },
      "source": [
        "## Coreference Resolution\n",
        "Coreference resolution identifies when different words or phrases in a text refer to the same entity. For example:\n",
        "\n",
        "Why is Coreference Resolution important?\n",
        "In medical documents, resolving coreferences ensures that all references to a patient, medication, or symptom are correctly attributed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7565WSEOcIqh"
      },
      "outputs": [],
      "source": [
        "nlp.add_pipe('coreferee')\n",
        "example_doc = nlp(example)\n",
        "\n",
        "example_doc._.coref_chains.print()\n",
        "example_doc._.coref_chains.resolve(example_doc[16])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploring Self-Hosted Large Language Models (LLMs)**\n",
        "\n",
        "Now that we’ve explored traditional NLP modules, it’s time to dive into the capabilities of self-hosted Large Language Models (LLMs). These powerful models excel at handling complex language tasks, offering advanced solutions for generating text, recognizing entities, and answering questions based on a given context.\n",
        "\n",
        "In this section, we will use LLMs to perform tasks such as text generation, Named Entity Recognition (NER), and Question Answering (QA). Hosting these models locally gives us greater control over their functionality and allows customization for specific domains, such as medical text analysis."
      ],
      "metadata": {
        "id": "Kz7INn2B1NLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Started\n",
        "In this section, we explore two approaches to working with Transformer-based models:\n",
        "\n",
        "Direct Model Loading:\n",
        "Use AutoTokenizer and AutoModelForCausalLM to load models manually. This approach provides flexibility and control over how models are used and configured\n",
        "\n",
        "Pipeline Helper:\n",
        "Use the pipeline API as a high-level interface for common NLP tasks like text generation, NER, or QA. This method simplifies implementation and is ideal for quick experimentation.\n",
        "These approaches allow us to tailor model usage to different levels of complexity and customization.\n",
        "\n",
        "The pipeline abstracts much of the complexity involved in tokenization, model interaction, and post-processing, allowing us to focus on solving real-world problems with minimal setup.\n",
        "\n",
        "An important difference to classical NLP pipelines is End-to-End Processing. It takes raw text as input and outputs task-specific results (e.g., text generation, question answering, sentiment analysis) without requiring explicit intermediate steps like tokenization or feature extraction."
      ],
      "metadata": {
        "id": "Ob6Kdz7tm19c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForTokenClassification\n",
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "v3p2yrhs3PWQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Generation with Transformers\n",
        "This example demonstrates how to generate text using a pre-trained language model with the Hugging Face pipeline API. By initializing a text-generation pipeline, we can easily create coherent continuations based on a given prompt.\n",
        "\n",
        "Prompt: A starting text is defined to guide the model in generating relevant content.\n",
        "Parameters: The max_length controls the output size, and num_return_sequences specifies how many variations to generate.\n",
        "Output: The generated text provides a natural continuation of the input prompt, showcasing the model's ability to create context-aware responses.\n",
        "\n",
        "**Question**: What can you observe if you run it multiple times?"
      ],
      "metadata": {
        "id": "eBJYbYaul44z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a text generation pipeline\n",
        "text_generator = pipeline(\"text-generation\")\n",
        "\n",
        "# Define a starting prompt (triple quotes allow multi-line strings)\n",
        "prompt = \"\"\"\n",
        "The patient was diagnosed with gastroesophageal reflux disease (GERD).\n",
        "The doctor prescribed a treatment plan including\n",
        "\"\"\"\n",
        "\n",
        "# Generate text using a pre-trained model with a specified token limit\n",
        "output = text_generator(prompt, max_length=150, num_return_sequences=1)\n",
        "\n",
        "# Print the generated text\n",
        "print(\"Generated Text:\")\n",
        "print(output[0]['generated_text'])"
      ],
      "metadata": {
        "id": "kYVu4sblH4Eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Named Entity Recognition\n",
        "This example demonstrates how to perform Named Entity Recognition (NER) using a pre-trained model and tokenizer. The pipeline API simplifies the process by providing a high-level interface for token classification tasks.\n",
        "\n",
        "Model and Tokenizer: A pre-trained model fine-tuned for NER is loaded, capable of identifying entities such as persons, locations, and organizations in text.\n",
        "\n",
        "Pipeline Setup: The pipeline is configured for NER, combining the model and tokenizer for seamless inference."
      ],
      "metadata": {
        "id": "_CljU9qNpLF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
        "\n",
        "# Create a pipeline for token classification\n",
        "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# You can also try the text we used for NLP\n",
        "text = \"Dr. Smith diagnosed John Doe with reflux in Heidelberg.\"\n",
        "# text = \"In the U.K., Joe Biden and Angela Merkel talked about the current economic situation. They both think the inflation rate will not drop in the near future!\"\n",
        "\n",
        "# Perform NER\n",
        "entities = nlp(text)\n",
        "for entity in entities:\n",
        "  print(entity)"
      ],
      "metadata": {
        "id": "IM_XGYTuptLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question Answering with Transformers\n",
        "\n",
        "This code showcases how to use a pre-trained Transformer model for Question Answering (QA). By providing a context (e.g., physician notes) and a natural language question, the model extracts relevant information directly from the text.\n",
        "\n",
        "**Experimentation Encouraged**\n",
        "\n",
        "Try Different Models: The pipeline allows you to swap models for QA tasks easily, offering flexibility to explore which model performs best for your data.\n",
        "\n",
        "Refine Your Prompts: Experiment with the phrasing of your questions to see how the model responds. Different prompts can yield varying levels of specificity or relevance in the answers."
      ],
      "metadata": {
        "id": "DrXwSLTPjDpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Question Answering pipeline\n",
        "# -> Try out different models!\n",
        "# - deepset/bert-base-cased-squad2\n",
        "# - allenai/longformer-base-4096\n",
        "# - distilbert/distilbert-base-cased-distilled-squad\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"dmis-lab/biobert-base-cased-v1.1\")\n",
        "\n",
        "\n",
        "# Combine physician letters\n",
        "text1 = \"\"\"\n",
        "The patient was prescribed Omprazle 20mg daily for acid reflux and heartburn. Aspirin was also given for pain relief.\n",
        "\"\"\"\n",
        "text2 = \"\"\"\n",
        "Pantoprazole was recommended for heartburn.\n",
        "\"\"\"\n",
        "text3 = \"\"\"\n",
        "Omaprazole 40mg daily.\n",
        "\"\"\"\n",
        "context = text1 + \" \" + text2 + \" \" + text3\n",
        "\n",
        "# -> Define your question and improve the prompt. Experiment a bit!\n",
        "question = \"Which medications for reflux are included?\"\n",
        "\n",
        "# Get the answer from the model\n",
        "result = qa_pipeline(question=question, context=context)\n",
        "\n",
        "# Interpret and display the result\n",
        "answer = result['answer']\n",
        "print(f\"Answer: {answer}\")"
      ],
      "metadata": {
        "id": "nDt2PMAYL8mW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discussion\n",
        "\n",
        "- Traditional NLP pipelines often require manual customization for specific domains (e.g., medicine, law). What challenges could this pose when working with highly specialized texts?\n",
        "- In what situations might rule-based or manually fine-tuned systems still be preferable to more automated approaches like Transformers?\n",
        "- Do you think there are tasks where a modular NLP pipeline might still outperform an integrated Transformer model?"
      ],
      "metadata": {
        "id": "dESlYyriVv6h"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}